{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho Final - Algebra Linear.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition\n",
        "!pip install ffmpeg\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNyTk9JA1dlO",
        "outputId": "eb1d761c-2606-4f0f-8076-426e21f74f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0+zzzcolab20220513001918)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.7/dist-packages (1.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Para a IA funcionar no colab corretamente é necessário uma GPU! Isto irá confirmar que uma GPU está ativa!\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWrb355M1m9p",
        "outputId": "56113652-5136-4a39-e3bd-4603cf55e90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 9954790805968185888\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14419755008\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 3569336994533595107\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "from moviepy.editor import *\n",
        "import moviepy.editor\n",
        "import ffmpeg\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "pPzLGp80vy5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def censura_rosto(filename, top, right, bottom, left):\n",
        "  \n",
        "  #Lendo e borrando toda a imagem usando Convolussão Gaussiana - Blur\n",
        "  image = cv2.imread(filename)\n",
        "  blurred_image = cv2.GaussianBlur(image,(153, 153), 0)\n",
        "\n",
        "  #Criando uma mask para delimitar a área borrada\n",
        "  roi_corners = np.array([[(left,top),(right,top),(right,bottom),(left,bottom)]],dtype = np.int32)\n",
        "  mask = np.zeros(image.shape, dtype=np.uint8)\n",
        "  channel_count = image.shape[2]\n",
        "  ignore_mask_color = (255,)*channel_count\n",
        "  cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
        "  mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask\n",
        "\n",
        "  #Juntando a mask e a imagem borrada\n",
        "  final_image = cv2.bitwise_and(blurred_image, mask) + cv2.bitwise_and(image, mask_inverse)\n",
        "  cv2.imwrite(filename,final_image)\n",
        "  "
      ],
      "metadata": {
        "id": "ulTDRk1n7zB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGOnQvLR1abS"
      },
      "outputs": [],
      "source": [
        "def censura_foto(filename, number_of_times_to_upsample = 2):\n",
        "\n",
        "  image = face_recognition.load_image_file(filename)\n",
        "  face_locations = face_recognition.face_locations(image, number_of_times_to_upsample)\n",
        "\n",
        "  for (top, right, bottom, left) in face_locations: \n",
        "    censura_rosto(filename, top, right, bottom, left)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extrai_video(filename):\n",
        "\n",
        "  #criando pasta para os frames\n",
        "  \n",
        "  os.makedirs(os.path.join(\"./\", \"video\"))\n",
        "\n",
        "  #extraindo o audio\n",
        "  clip = moviepy.editor.VideoFileClip(filename)\n",
        "  clip.audio.write_audiofile(\"./video/\" +\"audio.mp3\")\n",
        "\n",
        "  #extraindo os frames\n",
        "  vidcap = cv2.VideoCapture(filename)\n",
        "  success,image = vidcap.read()\n",
        "  count = 0 \n",
        "\n",
        "  while success:\n",
        "    cv2.imwrite(\"./video/\" + \"frame%s.jpg\" % str(count).zfill(8), image)     \n",
        "    success,image = vidcap.read()\n",
        "    count += 1\n",
        "\n",
        "  print(\"Frames extraidos!\")\n",
        "  vidcap.release()\n",
        "  cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "1ZLs_6A1BKio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def censura_video(filename, number_of_times_to_upsample = 1):  \n",
        "  #Atenção: Talvez seja possível fazer usando Batch para ser mais rápido na GPU, porém sempre falta memória!\n",
        "  extrai_video(filename)\n",
        "\n",
        "  files = glob.glob(f\"/content/video/*.jpg\")\n",
        "  files.sort()\n",
        "\n",
        "  for frames in tqdm(files, desc=\"Censurando os Frames... \" ):\n",
        "   censura_foto(frames, number_of_times_to_upsample)\n",
        "  \n",
        "  frame = cv2.imread(os.path.join(\"/content/video/\", files[0]))\n",
        "  height, width, layers = frame.shape\n",
        "  video = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 30, (width,height))\n",
        "\n",
        "  for frame in tqdm(files, desc=\"Criando o vídeo... \"):\n",
        "    video.write(cv2.imread(os.path.join(\"./\", frame)))\n",
        "  \n",
        "  cv2.destroyAllWindows()\n",
        "  video.release()\n",
        "\n",
        "  #juntando o audio do vídeo\n",
        "  print(\"Criando o Audio... \")\n",
        "  input_video = ffmpeg.input('./output.mp4')\n",
        "  input_audio = ffmpeg.input('./video/audio.mp3')\n",
        "  ffmpeg.concat(input_video, input_audio, v=1, a=1).output('./finished_video.mp4').run()\n",
        "\n",
        "  #Apagando a pasta \"./video/\" e o \"output.mp4\" para evitar mesclagem de frames\n",
        "  shutil.rmtree(os.path.join(\"./\", \"video\"))\n",
        "  os.remove(\"./output.mp4\")"
      ],
      "metadata": {
        "id": "gD7F5Xn3UCge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}